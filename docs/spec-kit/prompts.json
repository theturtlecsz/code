{
  "spec-plan": {
    "version": "20251002-plan-a",
    "gemini": {
      "role": "Researcher",
      "prompt": "Context:\n- Template: ~/.code/templates/plan-template.md (reference structure)\n- Workload: SPEC ${SPEC_ID} describes a feature or workload to be planned\n${CONTEXT}\nStructure aligns with plan-template.md.\n\nTask:\nBased on the workload described in SPEC ${SPEC_ID}, create research for planning. Summarize:\n1. Technical requirements and constraints for the workload.\n2. Related files/modules/tests relevant to implementing the workload.\n3. Potential risks or unknowns for the workload.\n4. Questions to clarify before planning the workload.\nKeep under 400 words. Cite file paths or memory IDs.\n\nOutput JSON:\n{\n  \"stage\": \"spec-plan\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gemini\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"research_summary\": [ { \"topic\": string, \"details\": string } ],\n  \"questions\": [ string ]\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "claude": {
      "role": "Synthesizer",
      "prompt": "Inputs:\n- SPEC packet describing the workload\n- Gemini research (${PREVIOUS_OUTPUTS.gemini})\n- Template: ~/.code/templates/plan-template.md (reference for output structure)\n\nTask:\nBased on the workload described in SPEC ${SPEC_ID}, create a detailed implementation plan. Include work breakdown, acceptance mapping, and risk analysis.\n\nProduce JSON:\n{\n  \"stage\": \"spec-plan\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"claude\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"work_breakdown\": [ { \"step\": string, \"rationale\": string, \"success_signal\": string } ],\n  \"acceptance_mapping\": [ { \"requirement\": string, \"validation_step\": string, \"artifact\": string } ],\n  \"risks\": [ { \"risk\": string, \"owner\": string, \"mitigation\": string } ]\n}\nFill arrays to match plan-template.md structure. Use ${PREVIOUS_OUTPUTS.gemini} for context. Return the JSON as your final response. The system will handle storage."
    },
    "gpt_pro": {
      "role": "Executor & QA",
      "prompt": "Inputs:\n- SPEC packet describing the workload\n- Gemini and Claude outputs (${PREVIOUS_OUTPUTS})\n- Template: ~/.code/templates/plan-template.md (structure reference)\n\nTask:\nValidate the feasibility of the plan for the workload described in SPEC ${SPEC_ID}. Ensure the plan is actionable and complete.\n\nEmit JSON:\n{\n  \"stage\": \"spec-plan\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gpt_pro\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"feasibility_notes\": [ string ],\n  \"missing_items\": [ string ],\n  \"final_plan\": {\n    \"work_breakdown\": [...copy of consensus steps...],\n    \"acceptance_mapping\": [...],\n    \"risks\": [...],\n    \"consensus\": { \"agreements\": [ string ], \"conflicts\": [ string ] }\n  }\n}\nJSON structure aligns with plan-template.md sections. Reference local evidence paths. Return the JSON as your final response. The system will handle storage."
    }
  },
  "spec-tasks": {
    "version": "20251002-tasks-a",
    "gemini": {
      "role": "Researcher",
      "prompt": "Context:\n- Template: ~/.code/templates/tasks-template.md (reference structure)\n- Plan: Based on plan for SPEC ${SPEC_ID}\n${CONTEXT}\nStructure aligns with tasks-template.md.\n\nTask:\nBased on the plan for SPEC ${SPEC_ID}, identify the technical surfaces and dependencies for implementing the workload. Research:\n1. Code areas and files that need modification for the workload.\n2. Tests that need creation or updates for the workload.\n3. Dependencies or blockers for implementing the workload.\n\nOutput JSON:\n{\n  \"stage\": \"spec-tasks\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gemini\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"surfaces\": [ { \"area\": string, \"files\": [string], \"tests\": [string], \"notes\": string } ],\n  \"dependencies\": [ string ],\n  \"spec_status\": [ { \"task_id\": string, \"status\": string } ]\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "claude": {
      "role": "Synthesizer",
      "prompt": "Template: ~/.code/templates/tasks-template.md\n\nInputs: SPEC packet describing the workload, Gemini analysis (${PREVIOUS_OUTPUTS.gemini}), Plan summary (${PREVIOUS_OUTPUTS.plan}).\n\nTask:\nBased on the plan for SPEC ${SPEC_ID}, decompose the workload into specific, implementable tasks. Each task should represent concrete work to build the features described in the SPEC.\n\nProduce JSON:\n{\n  \"stage\": \"spec-tasks\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"claude\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"tasks\": [ { \"order\": number, \"task_id\": string, \"title\": string, \"status\": string, \"validation_step\": string, \"artifact\": string, \"notes\": string } ],\n  \"acceptance_coverage\": [ string ],\n  \"followups\": [ string ]\n}\nEnsure acceptance mapping coverage and include lint/tests. Return the JSON as your final response. The system will handle storage."
    },
    "gpt_pro": {
      "role": "Executor & QA",
      "prompt": "Template: ~/.code/templates/tasks-template.md\n\nTask:\nValidate the task breakdown for SPEC ${SPEC_ID}. Ensure tasks are implementable, cover the full workload, and meet guardrail requirements (branch cleanliness, lint/test hooks).\n\nReview Gemini/Claude JSON outputs and emit JSON:\n{\n  \"stage\": \"spec-tasks\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gpt_pro\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"validated_tasks\": [...],\n  \"command_plan\": [ string ],\n  \"consensus\": { \"agreements\": [ string ], \"conflicts\": [ string ] }\n}\nReference SPEC.md update steps and docs paths. Return the JSON as your final response. The system will handle storage."
    }
  },
  "spec-implement": {
    "version": "20251002-implement-a",
    "gemini": {
      "prompt": "Template: ~/.code/templates/implement-template.md\n\nTask:\nBased on the tasks for SPEC ${SPEC_ID}, identify the code paths and integration points needed to implement the workload.\n\nGiven ${CONTEXT} and task list (${PREVIOUS_OUTPUTS.tasks}), emit JSON:\n{\n  \"stage\": \"spec-implement\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gemini\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"code_paths\": [ { \"area\": string, \"files\": [string], \"notes\": string } ],\n  \"recent_changes\": [ string ],\n  \"edge_cases\": [ string ],\n  \"tests\": [ string ]\n}\nFlag tricky integration points for the workload. Return the JSON as your final response. The system will handle storage."
    },
    "claude": {
      "prompt": "Template: ~/.code/templates/implement-template.md\n\nTask:\nBased on the tasks for SPEC ${SPEC_ID}, create an implementation strategy for the workload. Outline the specific file operations and validation approach.\n\nOutline implementation strategy as JSON:\n{\n  \"stage\": \"spec-implement\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"claude\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"approach\": [ { \"task_id\": string, \"summary\": string } ],\n  \"operations\": [ { \"file\": string, \"change_type\": string, \"description\": string } ],\n  \"validation_plan\": [ { \"command\": string, \"purpose\": string } ]\n}\nReference Gemini findings. Return the JSON as your final response. The system will handle storage."
    },
    "gpt_codex": {
      "prompt": "Template: ~/.code/templates/implement-template.md\n\nTask:\nGenerate code to implement the workload from SPEC ${SPEC_ID}. Provide specific diffs or code proposals based on the tasks and implementation strategy.\n\nEmit code diff proposals as JSON:\n{\n  \"stage\": \"spec-implement\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gpt_codex\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"diff_proposals\": [ { \"path\": string, \"change\": string (diff or summary), \"rationale\": string, \"confidence\": number } ],\n  \"test_commands\": [ string ],\n  \"tool_calls\": [ string ],\n  \"risks\": [ string ]\n}\nKeep output terse and focus on actionable edits for the workload. Return the JSON as your final response. The system will handle storage."
    },
    "gpt_pro": {
      "prompt": "Template: ~/.code/templates/implement-template.md\n\nTask:\nValidate the implementation approach for SPEC ${SPEC_ID}. Ensure code proposals are feasible and complete for the workload.\n\nValidate feasibility, schedule `/spec-ops-implement`, and output JSON:\n{\n  \"stage\": \"spec-implement\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gpt_pro\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"checklist\": [ { \"step\": string, \"command\": string } ],\n  \"risks\": [ { \"risk\": string, \"mitigation\": string } ],\n  \"consensus\": { \"agreements\": [ string ], \"conflicts\": [ string ] }\n}\nApply diffs only when orchestrator runs. Return the JSON as your final response. The system will handle storage."
    }
  },
  "spec-validate": {
    "version": "20251002-validate-a",
    "gemini": {
      "prompt": "Template: ~/.code/templates/validate-template.md\n\nTask:\nBased on the workload described in SPEC ${SPEC_ID}, create a comprehensive validation plan. Define test scenarios, coverage requirements, and validation criteria for the implemented features.\n\nEmit JSON:\n{\n  \"stage\": \"spec-validate\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gemini\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"scenarios\": [ { \"name\": string, \"type\": string, \"coverage\": string, \"acceptance_criteria\": string } ],\n  \"test_strategy\": [ string ],\n  \"rollback_plan\": string\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "claude": {
      "prompt": "Template: ~/.code/templates/validate-template.md\n\nTask:\nBased on the validation plan from Gemini and the workload in SPEC ${SPEC_ID}, map acceptance criteria to test scenarios. Ensure complete coverage of requirements.\n\nOutput JSON:\n{\n  \"stage\": \"spec-validate\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"claude\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"acceptance_mapping\": [ { \"requirement\": string, \"test_scenarios\": [string], \"coverage\": string } ],\n  \"gaps\": [ string ],\n  \"recommendations\": [ string ]\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "gpt_pro": {
      "prompt": "Template: ~/.code/templates/validate-template.md\n\nTask:\nReview the validation plan for SPEC ${SPEC_ID} and finalize it. Ensure the plan is comprehensive, executable, and covers all acceptance criteria for the workload.\n\nDeliver final validation plan as JSON:\n{\n  \"stage\": \"spec-validate\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gpt_pro\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"final_plan\": {\n    \"test_scenarios\": [...],\n    \"coverage_analysis\": string,\n    \"estimated_cost\": string,\n    \"monitoring_kpis\": [string]\n  },\n  \"consensus\": { \"agreements\": [ string ], \"conflicts\": [ string ] }\n}\nReturn the JSON as your final response. The system will handle storage."
    }
  },
  "spec-audit": {
    "version": "20251002-audit-a",
    "gemini": {
      "prompt": "Template: ~/.code/templates/audit-template.md\n\nTask:\nAudit the implementation and validation plan for the workload in SPEC ${SPEC_ID}. Check for completeness, quality, security, and compliance.\n\nCollect audit artifacts and emit JSON:\n{\n  \"stage\": \"spec-audit\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gemini\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"implementation_review\": string,\n  \"security_concerns\": [ string ],\n  \"quality_checks\": [ { \"item\": string, \"status\": string } ],\n  \"compliance_flags\": [ string ]\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "claude": {
      "prompt": "Template: ~/.code/templates/audit-template.md\n\nTask:\nBased on Gemini's audit and the complete work for SPEC ${SPEC_ID}, synthesize an audit decision. Assess if the workload implementation is ready for production.\n\nDraft audit memo as JSON:\n{\n  \"stage\": \"spec-audit\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"claude\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"audit_decision\": string,\n  \"readiness_assessment\": string,\n  \"risks\": [ { \"risk\": string, \"mitigation\": string } ],\n  \"open_items\": [ string ]\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "gpt_pro": {
      "prompt": "Template: ~/.code/templates/audit-template.md\n\nTask:\nFinalize the audit for SPEC ${SPEC_ID}. Review all audit findings and make a final recommendation on the workload implementation.\n\nVerify guardrails and output JSON:\n{\n  \"stage\": \"spec-audit\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gpt_pro\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"final_checks\": [ { \"item\": string, \"status\": string } ],\n  \"recommendation\": string,\n  \"conditions_for_approval\": [ string ],\n  \"consensus\": { \"agreements\": [ string ], \"conflicts\": [ string ] }\n}\nReturn the JSON as your final response. The system will handle storage."
    }
  },
  "spec-unlock": {
    "version": "20251002-unlock-a",
    "gemini": {
      "prompt": "Template: ~/.code/templates/unlock-template.md\n\nTask:\nReview the completed work for SPEC ${SPEC_ID}. Assess if the workload implementation is complete, tested, audited, and ready for unlock.\n\nExplain completion status as JSON:\n{\n  \"stage\": \"spec-unlock\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gemini\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"completion_summary\": string,\n  \"remaining_work\": [ string ],\n  \"unlock_blockers\": [ string ]\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "claude": {
      "prompt": "Template: ~/.code/templates/unlock-template.md\n\nTask:\nBased on Gemini's completion review and the full workload for SPEC ${SPEC_ID}, write an unlock justification. Determine if the work is ready to ship.\n\nWrite unlock justification memo as JSON:\n{\n  \"stage\": \"spec-unlock\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"claude\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"unlock_justification\": string,\n  \"readiness_assessment\": string,\n  \"safeguards\": [ string ],\n  \"followups\": [ string ]\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "gpt_pro": {
      "prompt": "Template: ~/.code/templates/unlock-template.md\n\nTask:\nMake the final unlock decision for SPEC ${SPEC_ID}. Review all completed work, audit results, and unlock justifications. Decide: UNLOCK or BLOCK.\n\nCheck guardrail compliance and decide unlock as JSON:\n{\n  \"stage\": \"spec-unlock\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gpt_pro\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"unlock_decision\": \"UNLOCK\"|\"BLOCK\",\n  \"decision_rationale\": string,\n  \"next_steps\": [ string ],\n  \"consensus\": { \"agreements\": [ string ], \"conflicts\": [ string ] }\n}\nReturn the JSON as your final response. The system will handle storage."
    }
  },
  "spec-auto": {
    "version": "20251002-auto-notes-a",
    "orchestrator_notes": [
      "Before each stage: ensure guardrail shell succeeded; fan out prompts above; collect outputs.",
      "Rust orchestrator automatically stores agent outputs to SQLite database with full traceability.",
      "On failure: emit resume token {stage, reason, suggested fix}."
    ]
  },
  "spec-clarify": {
    "version": "20251028-clarify-a",
    "gemini": {
      "role": "Ambiguity Scout",
      "prompt": "Context surfaces:\n- SPEC packet excerpts\n- PRD sections for ${SPEC_ID}\n- Prior consensus artifacts (plan/tasks if available)\n${CONTEXT}\n\nTask:\nIdentify up to five unresolved ambiguities that would block implementation. For each, attempt an authoritative answer based on industry norms or existing requirements.\n\nOutput JSON:\n{\n  \"stage\": \"spec-clarify\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gemini\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"issues\": [ {\n      \"id\": string,\n      \"question\": string,\n      \"proposed_answer\": string|null,\n      \"confidence\": \"high\"|\"medium\"|\"low\",\n      \"magnitude\": \"critical\"|\"important\"|\"minor\",\n      \"resolvability\": \"auto-fix\"|\"suggest-fix\"|\"need-human\",\n      \"reasoning\": string,\n      \"evidence\": [string]\n  } ]\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "claude": {
      "role": "Consensus Resolver",
      "prompt": "Inputs:\n- SPEC + PRD extracts\n- Gemini findings (${PREVIOUS_OUTPUTS.gemini})\n- Any prior stage syntheses\n\nTask:\nValidate or refine ambiguity answers, escalating anything that must go back to product/architecture.\n\nOutput JSON:\n{\n  \"stage\": \"spec-clarify\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"claude\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"issues\": [ {\n      \"id\": string,\n      \"question\": string,\n      \"answer\": string|null,\n      \"confidence\": \"high\"|\"medium\"|\"low\",\n      \"magnitude\": \"critical\"|\"important\"|\"minor\",\n      \"resolvability\": \"auto-fix\"|\"suggest-fix\"|\"need-human\",\n      \"reasoning\": string,\n      \"followup_action\": string|null\n  } ],\n  \"open_questions\": [ string ]\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "code": {
      "role": "Implementation Lens",
      "prompt": "Focus on technical blockers for SPEC ${SPEC_ID}. Combine SPEC/PRD context with plan/tasks (if any) to answer: what do engineers still need to know?\n\nOutput JSON:\n{\n  \"stage\": \"spec-clarify\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"code\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"issues\": [ {\n      \"id\": string,\n      \"question\": string,\n      \"answer\": string|null,\n      \"confidence\": \"high\"|\"medium\"|\"low\",\n      \"magnitude\": \"critical\"|\"important\"|\"minor\",\n      \"resolvability\": \"auto-fix\"|\"suggest-fix\"|\"need-human\",\n      \"reasoning\": string,\n      \"related_files\": [string]\n  } ],\n  \"implementation_notes\": [ string ]\n}\nReturn the JSON as your final response. The system will handle storage."
    }
  },
  "spec-analyze": {
    "version": "20251028-analyze-a",
    "gemini": {
      "role": "Consistency Auditor",
      "prompt": "Artifacts provided:\n${ARTIFACTS}\n\nGoal: Cross-check SPEC ${SPEC_ID} against downstream documents (plan/tasks/PRD). Flag gaps, contradictions, and terminology drift.\n\nOutput JSON mirrors quality-gate analyze schema but adds traceability:\n{\n  \"stage\": \"spec-analyze\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"gemini\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"issues\": [ {\n      \"id\": string,\n      \"type\": \"missing_requirement\"|\"terminology\"|\"contradiction\"|\"coverage_gap\",\n      \"description\": string,\n      \"severity\": \"critical\"|\"important\"|\"minor\",\n      \"affected_artifacts\": [string],\n      \"suggested_fix\": string|null,\n      \"confidence\": \"high\"|\"medium\"|\"low\",\n      \"resolvability\": \"auto-fix\"|\"suggest-fix\"|\"need-human\"\n  } ]\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "claude": {
      "role": "Validator",
      "prompt": "Use SPEC, PRD, plan, tasks (if present) plus Gemini's findings (${PREVIOUS_OUTPUTS.gemini}) to validate coverage. Escalate anything that threatens acceptance criteria.\n\nOutput JSON identical to spec-analyze schema but may collapse/merge issues. Include \"proposed_action\" when fix is obvious. Return the JSON as your final response. The system will handle storage."
    },
    "code": {
      "role": "Implementation Checker",
      "prompt": "From an engineering perspective, inspect references (files/tests) suggested by plan/tasks. Surface contradictions or missing detail that would break implementation.\n\nEmit the same spec-analyze JSON, adding \"implementation_hint\" inside each issue when a remediation command or file path is known. Return the JSON as your final response. The system will handle storage."
    }
  },
  "spec-checklist": {
    "version": "20251028-checklist-a",
    "claude": {
      "role": "Quality Assessor",
      "prompt": "Evaluate requirement quality in SPEC ${SPEC_ID} (or PRD if SPEC delegates). Score using 0-10 rubric and note improvements.\n\nOutput JSON:\n{\n  \"stage\": \"spec-checklist\",\n  \"prompt_version\": \"${PROMPT_VERSION}\",\n  \"agent\": \"claude\",\n  \"model\": \"${MODEL_ID}\",\n  \"model_release\": \"${MODEL_RELEASE}\",\n  \"reasoning_mode\": \"${REASONING_MODE}\",\n  \"requirements\": [ {\n      \"id\": string,\n      \"text\": string,\n      \"scores\": {\n        \"specificity\": number,\n        \"testability\": number,\n        \"completeness\": number,\n        \"clarity\": number\n      },\n      \"overall\": number,\n      \"needs_improvement\": boolean,\n      \"suggested_improvement\": string|null,\n      \"confidence\": \"high\"|\"medium\"|\"low\",\n      \"resolvability\": \"auto-fix\"|\"suggest-fix\"|\"need-human\"\n  } ],\n  \"summary\": string\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "code": {
      "role": "Implementation Assessor",
      "prompt": "Score requirements from implementability standpoint—focus on missing technical detail, test hooks, and integration clarity. Reuse spec-checklist JSON schema and ensure \"suggested_improvement\" points to specific files/tests when possible. Return the JSON as your final response. The system will handle storage."
    },
    "gemini": {
      "role": "Requirement Scorer",
      "prompt": "Provide a quick first pass scoring (same schema) emphasising completeness and ambiguities. Keep feedback concise (<40 words per requirement). Return the JSON as your final response. The system will handle storage."
    }
  },
  "quality-gate-clarify": {
    "version": "20251016-clarify-gate-a",
    "gemini": {
      "role": "Ambiguity Detector",
      "prompt": "Analyze SPEC ${SPEC_ID} for ambiguities, unclear requirements, or missing details.\n\nClassification Rules:\n- confidence: high (obvious ambiguity), medium (probable), low (uncertain)\n- magnitude: critical (blocks progress), important (significant), minor (nice-to-have)\n- resolvability: auto-fix (industry standard/obvious), suggest-fix (reasonable default), need-human (judgment required)\n\nOutput JSON:\n{\n  \"stage\": \"quality-gate-clarify\",\n  \"agent\": \"gemini\",\n  \"model\": \"${MODEL_ID}\",\n  \"issues\": [\n    {\n      \"id\": string,\n      \"question\": string,\n      \"answer\": string (your answer),\n      \"confidence\": \"high\"|\"medium\"|\"low\",\n      \"magnitude\": \"critical\"|\"important\"|\"minor\",\n      \"resolvability\": \"auto-fix\"|\"suggest-fix\"|\"need-human\",\n      \"reasoning\": string,\n      \"context\": string,\n      \"affected_requirements\": [string]\n    }\n  ]\n}\n\nAuto-fix examples: \"Log errors?\"→yes, \"HTTPS?\"→yes (security). Escalate architectural decisions. Return the JSON as your final response. The system will handle storage."
    },
    "claude": {
      "role": "Ambiguity Resolver",
      "prompt": "CRITICAL: You MUST return valid JSON with ACTUAL DATA, not the schema template.\n\nReview SPEC ${SPEC_ID} for unclear or ambiguous requirements.\n\nFor each ambiguity:\n1. Determine if answer is obvious (industry standard, security best practice)\n2. Classify confidence based on your certainty\n3. Assess impact (critical architectural decision vs minor detail)\n\nEXAMPLE OUTPUT (use as reference, replace with YOUR analysis):\n{\n  \"stage\": \"quality-gate-clarify\",\n  \"agent\": \"claude\",\n  \"model\": \"claude-haiku-4.5\",\n  \"issues\": [\n    {\n      \"id\": \"AUTH-METHOD\",\n      \"question\": \"Which authentication method should be used?\",\n      \"answer\": \"OAuth2 with JWT tokens (industry standard for APIs)\",\n      \"confidence\": \"high\",\n      \"magnitude\": \"important\",\n      \"resolvability\": \"auto-fix\",\n      \"reasoning\": \"OAuth2 is the security standard for modern APIs\",\n      \"context\": \"Security requirements section\"\n    }\n  ]\n}\n\nYOUR OUTPUT FORMAT (fill with actual analysis, NOT type annotations):\n{\n  \"stage\": \"quality-gate-clarify\",\n  \"agent\": \"claude\",\n  \"model\": \"${MODEL_ID}\",\n  \"issues\": [ /* your actual issues here, not 'string' placeholders */ ]\n}\n\nDo NOT return the template. Be conservative: if unsure or critical, mark need-human."
    },
    "code": {
      "role": "Implementation Validator",
      "prompt": "Identify ambiguities in SPEC ${SPEC_ID} from implementation perspective.\n\nFocus on:\n- Missing technical details (APIs, data formats, protocols)\n- Unclear acceptance criteria\n- Implementation assumptions\n\nOutput JSON:\n{\n  \"stage\": \"quality-gate-clarify\",\n  \"agent\": \"code\",\n  \"model\": \"${MODEL_ID}\",\n  \"issues\": [\n    {\n      \"id\": string,\n      \"question\": string,\n      \"answer\": string (technical answer),\n      \"confidence\": \"high\"|\"medium\"|\"low\",\n      \"magnitude\": \"critical\"|\"important\"|\"minor\",\n      \"resolvability\": \"auto-fix\"|\"suggest-fix\"|\"need-human\",\n      \"reasoning\": string,\n      \"context\": string\n    }\n  ]\n}\n\nMark architectural or business decisions as need-human. Return the JSON as your final response. The system will handle storage."
    }
  },
  "quality-gate-checklist": {
    "version": "20251016-checklist-gate-a",
    "gemini": {
      "role": "Requirement Scorer",
      "prompt": "Score each requirement in SPEC ${SPEC_ID} on 0-10 scale.\n\nCriteria:\n- Specificity: Concrete vs vague\n- Testability: Can verify completion\n- Completeness: All details present\n- Clarity: Unambiguous language\n\nFor requirements scoring <6.0, suggest improvement if obvious.\n\nOutput JSON:\n{\n  \"stage\": \"quality-gate-checklist\",\n  \"agent\": \"gemini\",\n  \"model\": \"${MODEL_ID}\",\n  \"requirements\": [\n    {\n      \"id\": string,\n      \"text\": string,\n      \"scores\": {\n        \"specificity\": number,\n        \"testability\": number,\n        \"completeness\": number,\n        \"clarity\": number\n      },\n      \"overall\": number (average),\n      \"needs_improvement\": boolean (<6.0),\n      \"suggested_improvement\": string|null,\n      \"confidence\": \"high\"|\"medium\"|\"low\",\n      \"resolvability\": \"auto-fix\"|\"suggest-fix\"|\"need-human\"\n    }\n  ]\n}\nReturn the JSON as your final response. The system will handle storage."
    },
    "claude": {
      "role": "Quality Assessor",
      "prompt": "CRITICAL: You MUST return valid JSON with ACTUAL DATA, not the schema template.\n\nEvaluate requirement quality in SPEC ${SPEC_ID}. Score 0-10, suggest improvements.\n\nEXAMPLE OUTPUT (use as reference, replace with YOUR scores):\n{\n  \"stage\": \"quality-gate-checklist\",\n  \"agent\": \"claude\",\n  \"model\": \"claude-haiku-4.5\",\n  \"requirements\": [\n    {\n      \"id\": \"REQ-1\",\n      \"text\": \"System must authenticate users\",\n      \"scores\": {\"specificity\": 6.0, \"testability\": 7.0, \"completeness\": 5.0, \"clarity\": 8.0},\n      \"overall\": 6.5,\n      \"needs_improvement\": false,\n      \"suggested_improvement\": null,\n      \"confidence\": \"high\",\n      \"resolvability\": \"auto-fix\"\n    }\n  ]\n}\n\nYOUR OUTPUT FORMAT (fill with actual scores, NOT type annotations):\n{\n  \"stage\": \"quality-gate-checklist\",\n  \"agent\": \"claude\",\n  \"model\": \"${MODEL_ID}\",\n  \"requirements\": [ /* your actual requirement scores here */ ]\n}\n\nDo NOT return the template with 'string', 'number', 'boolean' placeholders."
    },
    "code": {
      "role": "Implementation Assessor",
      "prompt": "Score requirements in SPEC ${SPEC_ID} from implementability perspective.\n\nOutput JSON:\n{\n  \"stage\": \"quality-gate-checklist\",\n  \"agent\": \"code\",\n  \"model\": \"${MODEL_ID}\",\n  \"requirements\": [\n    {\n      \"id\": string,\n      \"text\": string,\n      \"scores\": {\"specificity\": number, \"testability\": number, \"completeness\": number, \"clarity\": number},\n      \"overall\": number,\n      \"needs_improvement\": boolean,\n      \"suggested_improvement\": string|null,\n      \"confidence\": \"high\"|\"medium\"|\"low\",\n      \"resolvability\": \"auto-fix\"|\"suggest-fix\"|\"need-human\"\n    }\n  ]\n}\nReturn the JSON as your final response. The system will handle storage."
    }
  },
  "quality-gate-analyze": {
    "version": "20251016-analyze-gate-a",
    "gemini": {
      "role": "Consistency Checker",
      "prompt": "CRITICAL INSTRUCTION: You MUST respond with ONLY valid JSON. No markdown, no explanations, no preamble. Start with { and end with }.\n\nTask: Check consistency between artifacts for SPEC ${SPEC_ID}.\n\nContext: ${ARTIFACTS} (spec.md, plan.md if post-plan, tasks.md if post-tasks)\n\nLook for:\n- Missing requirements in downstream artifacts\n- Terminology mismatches\n- Contradictions\n- Coverage gaps\n\nOutput ONLY this JSON structure (no other text):\n{\n  \"stage\": \"quality-gate-analyze\",\n  \"agent\": \"gemini\",\n  \"model\": \"${MODEL_ID}\",\n  \"issues\": [\n    {\n      \"id\": string,\n      \"type\": \"missing_requirement\"|\"terminology\"|\"contradiction\"|\"coverage_gap\",\n      \"description\": string,\n      \"severity\": \"critical\"|\"important\"|\"minor\",\n      \"affected_artifacts\": [string],\n      \"suggested_fix\": string|null,\n      \"confidence\": \"high\"|\"medium\"|\"low\",\n      \"resolvability\": \"auto-fix\"|\"suggest-fix\"|\"need-human\"\n    }\n  ]\n}\n\nDO NOT include any other content. Your response must be parseable by JSON.parse(). Start now with {:"
    },
    "claude": {
      "role": "Artifact Validator",
      "prompt": "CRITICAL: You MUST return valid JSON with ACTUAL DATA, not the schema template.\n\nValidate artifact consistency for SPEC ${SPEC_ID}.\n\nArtifacts: ${ARTIFACTS}\n\nEXAMPLE OUTPUT (use as reference, replace with YOUR findings):\n{\n  \"stage\": \"quality-gate-analyze\",\n  \"agent\": \"claude\",\n  \"model\": \"claude-haiku-4.5\",\n  \"issues\": [\n    {\n      \"id\": \"TERM-MISMATCH-1\",\n      \"type\": \"terminology\",\n      \"description\": \"Plan uses 'authentication' but spec uses 'login'\",\n      \"severity\": \"minor\",\n      \"affected_artifacts\": [\"plan.md\", \"spec.md\"],\n      \"suggested_fix\": \"Standardize on 'authentication' throughout\",\n      \"confidence\": \"high\",\n      \"resolvability\": \"auto-fix\"\n    }\n  ]\n}\n\nYOUR OUTPUT FORMAT (fill with actual issues, NOT type annotations):\n{\n  \"stage\": \"quality-gate-analyze\",\n  \"agent\": \"claude\",\n  \"model\": \"${MODEL_ID}\",\n  \"issues\": [ /* your actual consistency issues here */ ]\n}\n\nDo NOT return the template with 'string' placeholders."
    },
    "code": {
      "role": "Coverage Validator",
      "prompt": "Check that downstream artifacts cover all SPEC requirements.\n\nSPEC: ${SPEC_ID}\nArtifacts: ${ARTIFACTS}\n\nOutput JSON:\n{\n  \"stage\": \"quality-gate-analyze\",\n  \"agent\": \"code\",\n  \"model\": \"${MODEL_ID}\",\n  \"issues\": [\n    {\n      \"id\": string,\n      \"type\": string,\n      \"description\": string,\n      \"severity\": \"critical\"|\"important\"|\"minor\",\n      \"affected_artifacts\": [string],\n      \"suggested_fix\": string|null,\n      \"confidence\": \"high\"|\"medium\"|\"low\",\n      \"resolvability\": \"auto-fix\"|\"suggest-fix\"|\"need-human\"\n    }\n  ]\n}\nReturn the JSON as your final response. The system will handle storage."
    }
  },
  "gpt5-validation": {
    "version": "20251016-validation-a",
    "prompt": "You are validating a majority answer (2/3 agents agreed) for a quality gate issue.\n\nSPEC Content:\n${SPEC_CONTENT}\n\nPRD Content:\n${PRD_CONTENT}\n\nQuestion: ${QUESTION}\n\nAgent Answers:\n- Agent 1 (agrees): ${ANSWER_1} - Reasoning: ${REASONING_1}\n- Agent 2 (agrees): ${ANSWER_2} - Reasoning: ${REASONING_2}\n- Agent 3 (disagrees): ${ANSWER_3} - Reasoning: ${REASONING_3}\n\nMajority Answer: ${MAJORITY_ANSWER}\nDissenting Reasoning: ${DISSENT_REASONING}\n\nYour Task:\n1. Analyze SPEC intent and requirements context\n2. Evaluate if majority answer aligns with SPEC goals\n3. Consider if dissenting reasoning reveals valid concern\n4. Determine if majority should be applied or escalated\n\nOutput JSON:\n{\n  \"agrees_with_majority\": boolean,\n  \"reasoning\": string (detailed analysis),\n  \"recommended_answer\": string|null (if you disagree),\n  \"confidence\": \"high\"|\"medium\"|\"low\",\n  \"critical_flag\": boolean (true if issue is architectural/critical)\n}\n\nIf the dissenting view makes a valid point about SPEC intent, reject the majority. Return the JSON as your final response. The system will handle storage."
  }
}
